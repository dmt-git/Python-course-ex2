{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5ccddc7-1525-47a0-ace6-8c19aeafc386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "#import asyncio\n",
    "\n",
    "data_path = Path(Path.cwd(), 'data', 'hw1.db')\n",
    "url_search = 'https://hh.ru/search/vacancy'\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "url_api = 'https://api.hh.ru/vacancies'\n",
    "par = {'area': '113'\n",
    "       ,'text': 'middle python developer'\n",
    "       ,'search_field': 'description'\n",
    "       ,'professional_role': '96'\n",
    "       ,'items_on_page': '20'\n",
    "       ,'page': '0'\n",
    "      }\n",
    "table_name1, table_name2 = 'vacancies1', 'vacancies2'\n",
    "#Реализация заполнения двух таблиц vacancies1, vacancies2 одинаковой структуры\n",
    "#вакансиями с hh.ru\n",
    "#Таблицы должны быть созданы заранее в базе данных SQLite: hw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d69a866-5f38-4b6e-8695-1e7ad510e9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Данные из html-странички, запись в таблицу vacancies1\n",
    "def first_method():\n",
    "    links = []\n",
    "    page = 0\n",
    "    data_list = []\n",
    "    #Составляем список 100 ссылок на вакансии\n",
    "    while (len(data_list) < 100) and (page < 10):\n",
    "        par['page'] = str(page)\n",
    "        result = requests.get(url_search, headers = user_agent, params = par)\n",
    "        if result.status_code != 200:\n",
    "            page += 1\n",
    "            continue\n",
    "        soup = BeautifulSoup(result.content, 'lxml')\n",
    "    \n",
    "        links = [l['href'].partition('?')[0] for l in soup.find_all('a', attrs={'data-qa':\"serp-item__title\"})]\n",
    "        page += 1\n",
    "    \n",
    "        for url_vacancy in links:\n",
    "            result = requests.get(url_vacancy, headers=user_agent)\n",
    "            if result.status_code != 200:\n",
    "                continue\n",
    "            soup = BeautifulSoup(result.content, 'lxml')\n",
    "            dic_str = {}\n",
    "            #Название компании       \n",
    "            dic_str['company_name'] = soup.find('span', attrs={'data-qa':\"bloko-header-2\"}).get_text()\n",
    "            #Название позиции\n",
    "            dic_str['position'] = soup.find('h1', attrs={'data-qa':\"vacancy-title\"}).get_text()\n",
    "            #Описание вакансии\n",
    "            dic_str['job_description'] = soup.find('div', attrs={'data-qa':\"vacancy-description\"}).get_text()\n",
    "            #Ключевые навыки\n",
    "            dic_str['key_skills'] = '; '.join([s.get_text() for s \n",
    "                                               in soup.find_all('span', attrs={'data-qa':\"bloko-tag__text\"})\n",
    "                                              ])\n",
    "            if 'Python' not in dic_str['key_skills']: #Не берём, если отсутствует требование по Python\n",
    "                continue\n",
    "            data_list.append(dic_str)\n",
    "            time.sleep(0.5) #Если делать без паузы, то через много страниц может выдать ошибку страницы\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    try:\n",
    "        connection = sqlite3.connect(data_path)\n",
    "    except:\n",
    "        print(f\"Error: Проблема с файлом '{data_path}'\")\n",
    "    try:\n",
    "        df.to_sql(table_name1, connection, if_exists='replace', index=False)\n",
    "        print('1st method: ok')\n",
    "    except:\n",
    "        print(f\"Error: Проблема с записью таблицы {table_name1}\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c51f371d-96e1-4abd-b003-433fcfeeed15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd method: ok\n"
     ]
    }
   ],
   "source": [
    "#Данные по api\n",
    "def second_method():\n",
    "    links = []\n",
    "    page = 0\n",
    "    data_list = []\n",
    "    #Составляем список 100 ссылок на вакансии\n",
    "    while (len(data_list) < 100) and (page < 10):\n",
    "        par['page'] = str(page)\n",
    "        result = requests.get(url_api, params = par, headers = user_agent)\n",
    "        if result.status_code != 200:\n",
    "            page += 1\n",
    "            continue\n",
    "        result_json = result.json()\n",
    "        links = [l['url'].split('?')[0] for l in result_json['items']]\n",
    "        page += 1\n",
    "    \n",
    "        for url_vacancy in links:\n",
    "            result2 = requests.get(url_vacancy, headers = user_agent)\n",
    "            if result.status_code != 200:\n",
    "                continue\n",
    "    \n",
    "            result2_json = result2.json()\n",
    "            dic_str = {}\n",
    "            #Название компании       \n",
    "            dic_str['company_name'] = result2_json['employer']['name']\n",
    "            #Название позиции\n",
    "            dic_str['position'] = result2_json['name']\n",
    "            #Описание вакансии\n",
    "            dic_str['job_description'] = BeautifulSoup(result2_json['description'], 'lxml').get_text()\n",
    "            #Ключевые навыки\n",
    "            dic_str['key_skills'] = '; '.join([s['name'] for s in result2_json[\"key_skills\"]])\n",
    "            if 'Python' not in dic_str['key_skills']:  #Не берём, если отсутствует требование по Python             \n",
    "                continue\n",
    "            data_list.append(dic_str)\n",
    "            time.sleep(0.5) #Если делать без паузы, то через много страниц может выдать ошибку страницы\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    try:\n",
    "        connection = sqlite3.connect(data_path)\n",
    "    except:\n",
    "        print(f\"Error: Проблема с файлом '{data_path}'\")\n",
    "    try:\n",
    "        df.to_sql(table_name2, connection, if_exists='replace', index=False)\n",
    "        print('2nd method: ok')\n",
    "    except:\n",
    "        print(f\"Error: Проблема с записью таблицы {table_name2}\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd4da859-091a-4c3e-a255-962e621c31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_method()\n",
    "second_method()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
